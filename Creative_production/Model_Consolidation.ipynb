{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2UnQ4BaBSix"
   },
   "source": [
    "# Code to Download Videos & store in a single folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gYlAKXzO4jSZ",
    "outputId": "e33b4f29-39e8-416c-cd7b-9c5318fa487b"
   },
   "outputs": [],
   "source": [
    "# Mount the drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OOPCxSqV7FNh"
   },
   "outputs": [],
   "source": [
    "# Give a folder name & choose a adaccount\n",
    "acc_name = 'LLC'\n",
    "acc_no = 'act_153756323362240'\n",
    "global_score = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00r6ysbj7WAm",
    "outputId": "e9dcfdc8-94c6-4af2-9e7b-641e81dc7430"
   },
   "outputs": [],
   "source": [
    "!pip3 install -q boto3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01CR842Q7QAd",
    "outputId": "4613252f-f340-4d4c-9d4c-c78171202d99"
   },
   "outputs": [],
   "source": [
    "# Basic dependencies to download videos \n",
    "import boto3, os\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "import pandas as pd\n",
    "import requests, time\n",
    "import urllib\n",
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y8wggR6_7UlV"
   },
   "outputs": [],
   "source": [
    "# AWS credantials\n",
    "ACCESS_ID = 'AKIA526JIYRBRQU7FSKI'\n",
    "ACCESS_KEY = 'mf5J+4vb2m3c7YTQ8M2T4E4xFyq/P6nut3lCajOB'\n",
    "bucket = 'blkbox-machinelearning'\n",
    "url = 'https://blkbox-machinelearning.s3.us-west-1.amazonaws.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cJkVcpWA7pF7"
   },
   "outputs": [],
   "source": [
    "#Connect to s3 Service\n",
    "client = boto3.client('s3',\n",
    "         aws_access_key_id=ACCESS_ID,\n",
    "         aws_secret_access_key= ACCESS_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_LOiiju7tpu"
   },
   "outputs": [],
   "source": [
    "#client.list_objects(Bucket = bucket).get('Contents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lh-tMUOL7yvJ"
   },
   "outputs": [],
   "source": [
    "# Get names of all objects present in the folder for the particular adaccount\n",
    "names = []\n",
    "if client.list_objects(Bucket = bucket, Prefix=f'Videos/{acc_no}/').get('Contents'):\n",
    "            result = client.list_objects(Bucket = bucket, Prefix=f'Videos/{acc_no}/').get('Contents')\n",
    "            for obj in result:\n",
    "                names.append(obj['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qC96uF4L8Psg",
    "outputId": "7c85fb96-8ac1-4ffd-9966-8f4d14cd8d16"
   },
   "outputs": [],
   "source": [
    "# Get only names of video files that end with .mp4\n",
    "names = list(set([name for name in names if name.endswith(\".mp4\")]))\n",
    "print(f\"The total videos for adaccount {acc_no} is :\", len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_fNqs51o8okj"
   },
   "outputs": [],
   "source": [
    "#names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rhwmHEkU8tWo",
    "outputId": "1151bcb1-c74a-4b8f-f558-a141270ec7de"
   },
   "outputs": [],
   "source": [
    "names[60].index('ALL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sbpr8AT59NSh",
    "outputId": "f16f552a-a2fe-4797-d5d8-dbdb329c5e75"
   },
   "outputs": [],
   "source": [
    "# Remove Duplicate videos added to training videos to the adaccounts folder \n",
    "names\n",
    "for index, item in enumerate(names):\n",
    "    names[index] = names[index][27:-4]\n",
    "\n",
    "names = [name for name in names if 'GIF' not in name if 'gif' not in name if '(1' not in name if ')' not in name]\n",
    "print(f\"The total after removing duplicates videos for adaccount {acc_no} is :\", len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DNv10Mcd9k8z"
   },
   "outputs": [],
   "source": [
    "#Re-Combining all to create full paths \n",
    "full_paths = []\n",
    "for name in names:\n",
    "  path = os.path.join(url,f'Videos/{acc_no}', name)\n",
    "  path = path + '.mp4'\n",
    "  full_paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c39CAkHX_ddo"
   },
   "outputs": [],
   "source": [
    "#full_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ti05a39_fo0",
    "outputId": "cdef176f-8629-4f55-94bc-f235bd740ecf"
   },
   "outputs": [],
   "source": [
    "full_paths[0].index(\"ALL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9HMTjLpM_5nj"
   },
   "outputs": [],
   "source": [
    "# Creation of folder where video data will be stored\n",
    "if not os.path.exists(f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_ADS'):\n",
    "    os.makedirs(f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_ADS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8lQ92t_gAHVt",
    "outputId": "5f5a8cbe-20fe-4405-a453-9c234d5c6499"
   },
   "outputs": [],
   "source": [
    "# Function to download all images for training\n",
    "def download(url,name):\n",
    "  r = requests.get(url, allow_redirects=True)\n",
    "  open(f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_ADS/{name}', 'wb').write(r.content)\n",
    "  print(\"Download_Complete :\",name)\n",
    "\n",
    "count=0\n",
    "for video_path in full_paths:\n",
    "    #start = video_path.index('act_')\n",
    "    start = int(85)\n",
    "    end = video_path.index('.mp4')\n",
    "    #print(start)\n",
    "    #print(end)\n",
    "    name = video_path[start:end:1].replace('/','-')\n",
    "    download(url=video_path,name=name)\n",
    "    count += 1\n",
    "  \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIqDxVi5BiNd"
   },
   "source": [
    "# Code to Splitt Videos & Store in seperate folder with subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EbnFo9AfAXx4",
    "outputId": "f791debc-9e2c-49bc-e894-271ffb51f46d"
   },
   "outputs": [],
   "source": [
    "# Basic Dependencies for downloading\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "from moviepy.editor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feIjLjBcCJ47"
   },
   "outputs": [],
   "source": [
    "# Name of the directory where we want the splitted scenes to reside\n",
    "if not os.path.exists(f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_F_DATA'):\n",
    "    os.makedirs(f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_F_DATA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q0reY-D1CNtJ"
   },
   "outputs": [],
   "source": [
    "def list_full_paths(directory):\n",
    "    return [os.path.join(directory, file) for file in os.listdir(directory)]\n",
    "\n",
    "videos = list_full_paths(f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_ADS')\n",
    "data = os.listdir(f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_ADS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kqoe-2DDCa1b",
    "outputId": "c70202cf-6c12-4fb5-8ac0-fda38322e0b2"
   },
   "outputs": [],
   "source": [
    "print(len(videos))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3GXik1jDPn1",
    "outputId": "616481fd-8e8a-40c9-8d6b-af5f270ce825"
   },
   "outputs": [],
   "source": [
    "!pip install scenedetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4gjMZGRCm32"
   },
   "outputs": [],
   "source": [
    "#Basic Dependencies of PySceneDetect\n",
    "from scenedetect import VideoManager\n",
    "from scenedetect.video_splitter import split_video_ffmpeg\n",
    "from scenedetect import SceneManager\n",
    "from scenedetect.detectors import ContentDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yr5c5b3dDG8d"
   },
   "outputs": [],
   "source": [
    "def find_scenes(video_path, threshold):\n",
    "    # Create our video & scene managers, then add the detector.\n",
    "    video_manager = VideoManager([video_path])\n",
    "    scene_manager = SceneManager()\n",
    "    scene_manager.add_detector(\n",
    "        ContentDetector(threshold=threshold))\n",
    "\n",
    "    # Improve processing speed by downscaling before processing.\n",
    "    video_manager.set_downscale_factor()\n",
    "\n",
    "    # Start the video manager and perform the scene detection.\n",
    "    video_manager.start()\n",
    "    scene_manager.detect_scenes(frame_source=video_manager)\n",
    "\n",
    "    # Each returned scene is a tuple of the (start, end) timecode.\n",
    "    return scene_manager.get_scene_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbaQIfIbDVmK"
   },
   "outputs": [],
   "source": [
    "def split_scenes(video_path, scene_list, name):\n",
    "  # print(scene_list)\n",
    "  # print(os.getcwd())\n",
    "    os.chdir(f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_F_DATA')\n",
    "  # print(os.getcwd())\n",
    "    \n",
    "    if not os.path.exists(name):\n",
    "        os.makedirs(name)\n",
    "    print(os.getcwd())\n",
    "    os.chdir(f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_F_DATA/{name}')\n",
    "    print(os.getcwd())\n",
    "    split_video_ffmpeg([video_path], scene_list = scene_list, \n",
    "      output_file_template = '$VIDEO_NAME - Scene $SCENE_NUMBER.mp4', video_name = name)\n",
    "    # Each returned scene is a tuple of the (start, end) timecode.\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UPDKtiq4DaZI"
   },
   "outputs": [],
   "source": [
    "def check_video_threshold(video_path):\n",
    "  # Create an object by passing the location as a string\n",
    "  video_len = VideoFileClip(video_path)\n",
    "  \n",
    "  # getting duration of the video\n",
    "  video_duration = int(video_len.duration)\n",
    "\n",
    "  if video_duration <= 15:\n",
    "    threshold = 30.00\n",
    "  elif video_duration > 15 & video_duration < 30:\n",
    "    threshold = 30.00\n",
    "  return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "1mejHoGADeH5",
    "outputId": "ed23ec29-76fa-4158-ea38-eca7dd00340a"
   },
   "outputs": [],
   "source": [
    "# Call to above helper functions to split the videos\n",
    "counter = 0\n",
    "for video in videos:\n",
    "    video_path = video\n",
    "    #function to check the length of the videos and assign dynamic threshold\n",
    "  #  thres = check_video_threshold(video_path)\n",
    "    thres = 30\n",
    "    \n",
    "\n",
    "    #scenes = find_scenes(video_path)\n",
    "    scenes = find_scenes(video_path, thres)\n",
    "    split_scenes(video_path, scenes, data[counter])\n",
    "    counter += 1\n",
    "  # time.sleep(3)\n",
    "    print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sPlGTTzEDyQ-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ykIwxcTUXqx7",
    "outputId": "51307512-0194-46d6-a994-a3249ad4ae33"
   },
   "outputs": [],
   "source": [
    "image_dir = Path(f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_F_DATA')\n",
    "total=os.listdir(image_dir)\n",
    "print(len(total))\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LGSXv66fX2WU"
   },
   "outputs": [],
   "source": [
    "# Name of the directory where we want the splitted scenes to reside\n",
    "if not os.path.exists(f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_Training_Data'):\n",
    "    os.makedirs(f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_Training_Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qwP6XYlCYB4M"
   },
   "outputs": [],
   "source": [
    "root_path = f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_Training_Data/'\n",
    "folders = ['START','MID','END','Unseen_Start']\n",
    "for folder in folders:\n",
    "  try:\n",
    "    os.mkdir(os.path.join(root_path,folder))\n",
    "  except OSError:\n",
    "    os.mkdir(os.path.join(root_path,folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tr0mou7lYINF",
    "outputId": "5188ddc3-3d07-4647-9590-69f9e7770513"
   },
   "outputs": [],
   "source": [
    "# Test Paths\n",
    "total[1]\n",
    "filepaths = list(pd.Series(list(image_dir.glob(r'{}/*.mp4'.format(total[3]))), name='Filepath').astype(str))\n",
    "print(len(filepaths[0]))\n",
    "print(len(filepaths[1])) \n",
    "print(len(filepaths[1:-1]))\n",
    "print(\"All Paths\")\n",
    "print(filepaths)\n",
    "print(\"Start Scene\")\n",
    "print(filepaths[0])\n",
    "print(\"End Scene\")\n",
    "print(filepaths[-1])\n",
    "print(\"Mid Scenes\")\n",
    "print(filepaths[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "esTbuk-WYL_9",
    "outputId": "df125a7c-d40c-4b7f-da40-437a01b6ad7f"
   },
   "outputs": [],
   "source": [
    "#Copy all start scenes to start scene folder\n",
    "counter = 0\n",
    "for i in total:\n",
    "    filepaths = list(pd.Series(list(image_dir.glob(r'{}/*.mp4'.format(i))), name='Filepath').astype(str))\n",
    "    try:\n",
    "      print(filepaths[0])\n",
    "      shutil.copy2(filepaths[0],f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_Training_Data/START')\n",
    "      counter += 1\n",
    "    except:\n",
    "      pass\n",
    "    \n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xaRKxdFiYY7V",
    "outputId": "7fcdbb15-43dd-45ef-bb57-104519e54e60"
   },
   "outputs": [],
   "source": [
    "#End Scenes copy to seperate folder\n",
    "counter = 0 \n",
    "for i in total:\n",
    "    filepaths = list(pd.Series(list(image_dir.glob(r'{}/*.mp4'.format(i))), name='Filepath').astype(str))\n",
    "    try:\n",
    "      print(filepaths[-1])\n",
    "      shutil.copy2(filepaths[-1],f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_Training_Data/END')\n",
    "      counter += 1\n",
    "    except:\n",
    "      pass\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J0OaQthLYjKJ",
    "outputId": "97f26a2b-3bb2-4856-f793-5459c6c3da25"
   },
   "outputs": [],
   "source": [
    "#mid scenes copy to seperate folders\n",
    "counter = 0\n",
    "for i in total:\n",
    "    filepaths = list(pd.Series(list(image_dir.glob(r'{}/*.mp4'.format(i))), name='Filepath').astype(str))\n",
    "    filepaths = filepaths[1:-1]\n",
    "    print(filepaths[1:-1])\n",
    "    for c in filepaths:\n",
    "        shutil.copy2(c,f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_Training_Data/MID')\n",
    "    counter += 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N5NE9raSYvce",
    "outputId": "6a5cc76d-5040-4904-a153-7011dac5b8f1"
   },
   "outputs": [],
   "source": [
    "#Unseen_Start scenes collection\n",
    "counter = 0\n",
    "for i in total:\n",
    "    filepaths = list(pd.Series(list(image_dir.glob(r'{}/*.mp4'.format(i))), name='Filepath').astype(str))\n",
    "    try:\n",
    "      print(filepaths[0])\n",
    "      shutil.copy2(filepaths[0],f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_Training_Data/Unseen_Start')\n",
    "    except:\n",
    "      pass\n",
    "    counter += 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmjjrkxuZBtM"
   },
   "source": [
    "# Code for neural network & model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RbPCNlbOZG3I",
    "outputId": "8f089db1-e987-4021-8d39-40c987264b23"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 # extract frames from the videos\n",
    "from PIL import Image  # to manipulate images\n",
    "import os\n",
    "import psycopg2\n",
    "\n",
    "from tensorflow.keras.applications import DenseNet201, ResNet152, InceptionResNetV2, ResNet152V2, NASNetLarge\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from google.colab.patches import cv2_imshow\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import moviepy.editor\n",
    "# Import everything needed to edit video clips\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip, concatenate_videoclips, TextClip, CompositeVideoClip, concatenate_audioclips, AudioClip, CompositeAudioClip\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZcJqqhW6uSl"
   },
   "outputs": [],
   "source": [
    "def model_selector(model_name: str):\n",
    "  if model_name == \"inception\":\n",
    "    model = InceptionResNetV2(weights=\"imagenet\")   # requires shape (299, 299, 3)\n",
    "  elif model_name == \"nasnet\":\n",
    "    model = NASNetLarge(weights=\"imagenet\")   # requires shape (331, 331, 3)\n",
    "  elif model_name == \"resnet\":\n",
    "    model = ResNet152V2(weights=\"imagenet\")   # requires shape (224, 224, 3)\n",
    "  else:\n",
    "    print(\"Choose one of `inception`, `nasnet`, `resnet`\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RHUhHUEKZMOR",
    "outputId": "907acf29-3c8f-4803-c642-def8fd250c37"
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "\n",
    "model = model_selector(\"inception\")\n",
    "model.summary(line_length=200)\n",
    "# remove the last layers in order to get features instead of predictions\n",
    "\n",
    "feat_extractor = Model(inputs=model.input, outputs=model.get_layer(\"avg_pool\").output)    # for nasnet, change the layer name to global_average_pooling2d instead of avg_pool\n",
    "\n",
    "# print the layers of the CNN\n",
    "feat_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q1Zs-EPDZQUP"
   },
   "outputs": [],
   "source": [
    "# path & parameter setup\n",
    "\n",
    "video_path_mid = f\"/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_Training_Data/MID/\"\n",
    "video_path_end = f\"/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_Training_Data/END/\"\n",
    "target_path = f\"/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_Training_Data/Unseen_Start/\"\n",
    "video_model_width, video_model_height = 299, 299\n",
    "#No_of_frames = 2\n",
    "No_of_mid_scenes = 2\n",
    "No_of_end_scenes = 1\n",
    "clip_length = 2\n",
    "\n",
    "nb_closest_videos = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8_EpFyx0ZgFk",
    "outputId": "cbd858c7-497c-44ae-dd9f-00b80ac1f209"
   },
   "outputs": [],
   "source": [
    "# Function to check clip duration & remove short clips\n",
    "def clip_duration_checker(files):\n",
    "  f = []\n",
    "  for clip in files:\n",
    "    c = VideoFileClip(clip)\n",
    "    duration = c.duration\n",
    "    if duration > clip_length:\n",
    "      f.append(clip)\n",
    "  return f\n",
    "\n",
    "files_mid = [video_path_mid + x for x in os.listdir(video_path_mid) if \".mp4\" in x]\n",
    "#files_mid = np.random.choice(files_mid, 20)\n",
    "files_mid = list(set(files_mid))\n",
    "files_mid = clip_duration_checker(files_mid)\n",
    "print(\"number of videos in Mid :\",len(files_mid))\n",
    "\n",
    "files_end = [video_path_end + x for x in os.listdir(video_path_end) if \".mp4\" in x]\n",
    "#files_end = np.random.choice(files_end, 5)\n",
    "files_end = list(set(files_end))\n",
    "files_end = clip_duration_checker(files_end)\n",
    "print(\"number of videos in end:\",len(files_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AGxYZauKZmV6"
   },
   "outputs": [],
   "source": [
    "# Function Fetching Data directly from Database for global performance,tags,primary color & finding the dimension of video\n",
    "def global_performance(clip_name):\n",
    "  conn = psycopg2.connect(user = \"ds_readonly\", password = \"blkbox2020!\",host = \"db.blkbox.ai\",port = \"5432\",database = \"blkbox\")\n",
    "  sql = (\"select sum(distinct(global_performance)) as global_performance \"   \n",
    "        \"from fb_app_assets \"\n",
    "        \"where asset_name like '%{a}%' and asset_type = 'VIDEO' \"\n",
    "        \"order by global_performance desc; \".format(a=clip_name))\n",
    "  data = pd.read_sql_query(sql, conn)\n",
    "  conn = None\n",
    "  return max(data.global_performance,default=0)\n",
    "\n",
    "def all_video_ar(video):\n",
    "  # loading video dsa gfg intro video \n",
    "  clip = VideoFileClip(video) \n",
    "  # getting only first 5 seconds\n",
    "  clip = clip.subclip(0, 5) \n",
    "  # getting clip size\n",
    "  value = clip.size\n",
    "  return value\n",
    "\n",
    "def tag_search(clip_name):\n",
    "  conn = psycopg2.connect(user = \"ds_readonly\", password = \"blkbox2020!\",host = \"db.blkbox.ai\",port = \"5432\",database = \"blkbox\")\n",
    "  sql = (\"select tags from fb_app_assets \"\n",
    "        \"where adaccount_id = '{b}' and asset_name like '%{a}%' and asset_type = 'VIDEO' \"\n",
    "        \"order by global_performance desc; \".format(b=acc_no,a=clip_name))\n",
    "  data = pd.read_sql_query(sql, conn)\n",
    "  conn = None\n",
    "  return (data.tags[0])\n",
    "\n",
    "def primary_colors(clip_name):\n",
    "  conn = psycopg2.connect(user = \"ds_readonly\", password = \"blkbox2020!\",host = \"db.blkbox.ai\",port = \"5432\",database = \"blkbox\")\n",
    "  sql = (\"select primary_colors from fb_app_assets \"\n",
    "        \"where adaccount_id = '{b}' and asset_name like '%{a}%' and asset_type = 'VIDEO' \"\n",
    "        \"order by global_performance desc; \".format(b=acc_no,a=clip_name))\n",
    "  data = pd.read_sql_query(sql, conn)\n",
    "  conn = None\n",
    "  return (data.primary_colors[0])\n",
    "\n",
    "def performance_df(files,section):\n",
    "  counter = 0\n",
    "  performance = []\n",
    "  dimension = []\n",
    "  tags = []\n",
    "  primary_color = []\n",
    "  video_name_list = []\n",
    "  for video in files:\n",
    "    s1 = video\n",
    "    s2 = \"{a}/\".format(a=section)\n",
    "    s3 = \" - Scene\"\n",
    "\n",
    "    name = s1[s1.index(s2) + len(s2):s1.index(s3)]\n",
    "    video_name_list.append(name)\n",
    "    performance.append(global_performance(name))\n",
    "    dimension.append(all_video_ar(video))\n",
    "    tags.append(tag_search(name))\n",
    "    primary_color.append(primary_colors(name))\n",
    "    \n",
    "  print(len(video_name_list))\n",
    "  print(len(performance))\n",
    "  print(len(files))\n",
    "  print(len(dimension))\n",
    "  print(len(tags))\n",
    "  print(len(primary_color))\n",
    "  df = pd.DataFrame(list(zip(video_name_list, files, performance, dimension, tags, primary_color)),columns =['video_name','files_path','performance','dimension','tags', 'primary_color'])\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GW2s0Lppcyqe",
    "outputId": "d8563a94-6c28-4c79-b3a3-45a757f64555"
   },
   "outputs": [],
   "source": [
    "df_mid_performance = performance_df(files_mid,'MID')\n",
    "df_end_performance = performance_df(files_end,'END')\n",
    "df_mid_performance['performance'] = df_mid_performance['performance'].fillna(0)\n",
    "df_end_performance['performance'] = df_end_performance['performance'].fillna(0)\n",
    "#print(df_mid_performance.head(30))\n",
    "#print(df_end_performance.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "dl73ieHWfTcE",
    "outputId": "071ac4b1-227d-4db6-d9ff-6950fd84e757"
   },
   "outputs": [],
   "source": [
    "df_mid_performance.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mKa4XQ9rdswm"
   },
   "outputs": [],
   "source": [
    "# Function to extract features from train mid, end , target\n",
    "def getFirstFrame(vs):\n",
    "  success, image = vs.read()\n",
    "  #TODO: Change dim according to model\n",
    "  image = cv2.resize(image, (299, 299))\n",
    "  if success:\n",
    "#       cv2_imshow(image)\n",
    "      return image\n",
    "\n",
    "def getLastFrame(vs):\n",
    "  last_frame_num = vs.get(cv2.CAP_PROP_FRAME_COUNT) - 1\n",
    "  print(last_frame_num)\n",
    "  vs.set(cv2.CAP_PROP_POS_FRAMES, last_frame_num)\n",
    "  success, image = vs.read()\n",
    "  \n",
    "  image = cv2.resize(image, (299, 299))\n",
    "  if success:\n",
    " #     cv2_imshow(image)\n",
    "      return image\n",
    "\n",
    "def feature_extractor(files,section):  \n",
    "  importedvideos = []\n",
    "  # load all the images and prepare them for feeding into the CNN\n",
    "  counter = 0\n",
    "\n",
    "  for video in tqdm(files):  \n",
    "        frames = []\n",
    "       # count = 1\n",
    "\n",
    "        path = video\n",
    "        print(path)\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        if section == \"END\" or \"Target\":\n",
    "          img = getFirstFrame(cap)\n",
    "          frames.append(img)\n",
    "          img = getLastFrame(cap)\n",
    "          frames.append(img)\n",
    "        elif section == \"MID\":\n",
    "          img = getLastFrame(cap)\n",
    "          frames.append(img)\n",
    "          img = getFirstFrame(cap)\n",
    "          frames.append(img)\n",
    "        video_frames = np.stack(frames, axis=0)  \n",
    "        # extract the images features\n",
    "\n",
    "        imgs_features = feat_extractor.predict(video_frames)\n",
    "\n",
    "        print(\"features successfully extracted!\")\n",
    "        print(imgs_features.shape)\n",
    "\n",
    "        flatten_img_features = imgs_features.flatten()\n",
    "        print(flatten_img_features.shape)\n",
    "     \n",
    "        flatten_img_features = np.expand_dims(flatten_img_features,axis = 0)\n",
    "\n",
    "    \n",
    "\n",
    "    #    flatten_img_features = np.expand_dims(flatten_img_pca,axis = 0)\n",
    "        print(flatten_img_features.shape)\n",
    "    #   if flatten_img_features.shape[1] == 19200:\n",
    "        importedvideos.append(flatten_img_features)\n",
    "        \n",
    "        \n",
    "  videos_array = np.vstack(importedvideos)\n",
    "  \n",
    "  return videos_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yrlq-qbrjnt1"
   },
   "outputs": [],
   "source": [
    "# Name of the directory where we want the splitted scenes to reside\n",
    "if not os.path.exists(f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_ARRAY_STORAGE'):\n",
    "    os.makedirs(f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_ARRAY_STORAGE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hiPcBsdqjuzY",
    "outputId": "8fa54b81-d866-45bd-98f3-add5178f6bbf"
   },
   "outputs": [],
   "source": [
    "videos_mid_train = feature_extractor(files_mid,'MID')\n",
    "np.save(f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_ARRAY_STORAGE/videos_mid_train', videos_mid_train)\n",
    "file_name = f\"/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_ARRAY_STORAGE/{acc_name}_files_mid\"\n",
    "open_file = open(file_name, \"wb\")\n",
    "pickle.dump(files_mid, open_file)\n",
    "open_file.close()\n",
    "\n",
    "df_mid_performance.to_pickle(f\"/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_ARRAY_STORAGE/df_mid_performance\")\n",
    "\n",
    "print(files_mid)\n",
    "print(len(files_mid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vLnRiwv4j4vB",
    "outputId": "575f24da-f3f7-4cb0-b2a9-e4dfb529a203"
   },
   "outputs": [],
   "source": [
    "videos_end_train = feature_extractor(files_end,'END')\n",
    "np.save(f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_ARRAY_STORAGE/videos_end_train', videos_end_train)\n",
    "file_name = f\"/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_ARRAY_STORAGE/{acc_name}_files_end\"\n",
    "open_file = open(file_name, \"wb\")\n",
    "pickle.dump(files_end, open_file)\n",
    "open_file.close()\n",
    "\n",
    "df_end_performance.to_pickle(f\"/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_ARRAY_STORAGE/df_end_performance\")\n",
    "\n",
    "\n",
    "print(files_end)\n",
    "print(len(files_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBo_ilw9lYyw",
    "outputId": "93964243-8f6a-426d-e949-4ef30e44ebfe"
   },
   "outputs": [],
   "source": [
    "# target\n",
    "target = [target_path + x for x in os.listdir(target_path) if \".mp4\" in x]\n",
    "#files1 = np.random.choice(files1, 3)\n",
    "print(\"number of Videos:\",len(target))\n",
    "\n",
    "target = list(target)\n",
    "print(len(target))\n",
    "a = []\n",
    "for vid in target:\n",
    "      video = moviepy.editor.VideoFileClip(vid)\n",
    "      video_duration = int(video.duration)\n",
    "    #  print(video_duration)\n",
    "      if video_duration > 2:\n",
    "        a.append(vid)\n",
    "        \n",
    "target = a\n",
    "print(len(target))\n",
    "\n",
    "df_target_performance = performance_df(target,'Unseen_Start')\n",
    "#df_Unseen_performance = performance_df(target,'Unseen_Start')\n",
    "df_target_performance['performance'] = df_mid_performance['performance'].fillna(0)\n",
    "print(df_target_performance.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OEJn6GOQn1mR"
   },
   "outputs": [],
   "source": [
    "df_target_performance = df_target_performance.sort_values(by=['performance'], ascending=False)\n",
    "df_target_performance.to_pickle(f\"/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_ARRAY_STORAGE/df_target_performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "hU0pB3dFmHuP",
    "outputId": "4ce12e29-d53e-4c84-9d52-af05b31974d7"
   },
   "outputs": [],
   "source": [
    "df_target_performance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LvvJ6H17ox_0",
    "outputId": "788a1db6-8102-405b-8d2a-343e9f112fba"
   },
   "outputs": [],
   "source": [
    "# Test code starts here, reload back video array, dataframe etc in the respective variables\n",
    "videos_mid_train = np.load(f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_ARRAY_STORAGE/videos_mid_train.npy')\n",
    "file_name = f\"/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_ARRAY_STORAGE/{acc_name}_files_mid\"  \n",
    "open_file = open(file_name, \"rb\")\n",
    "files_mid = pickle.load(open_file)\n",
    "open_file.close()\n",
    "df_mid_performance = pd.read_pickle(f\"/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_ARRAY_STORAGE/df_mid_performance\")\n",
    "\n",
    "print(videos_mid_train.shape)\n",
    "print(len(files_mid))\n",
    "print(df_mid_performance.shape)\n",
    "\n",
    "\n",
    "videos_end_train = np.load(f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_ARRAY_STORAGE/videos_end_train.npy') \n",
    "file_name = f\"/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_ARRAY_STORAGE/{acc_name}_files_end\"\n",
    "open_file = open(file_name, \"rb\")\n",
    "files_end = pickle.load(open_file)\n",
    "open_file.close()\n",
    "df_end_performance = pd.read_pickle(f\"/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_ARRAY_STORAGE/df_end_performance\")\n",
    "\n",
    "\n",
    "df_target_performance = pd.read_pickle(f\"/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_ARRAY_STORAGE/df_target_performance\")\n",
    "\n",
    "print(videos_end_train.shape)\n",
    "print(len(files_end))\n",
    "print(df_end_performance.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TN2SQdH4pRf3",
    "outputId": "0bfd540e-ed4a-4e3d-f7bc-acafba9ddebe"
   },
   "outputs": [],
   "source": [
    "# Select target scene from top 10 performing scene\n",
    "target = list(df_target_performance.files_path.head(10))\n",
    "\n",
    "t = target[2]\n",
    "target = []\n",
    "target.append(t)\n",
    "target\n",
    "\n",
    "# ['/content/gdrive/MyDrive/Scene-Detection-Version-2/LLC_Training_Data/Unseen_Start/ALL_LLC_BuffaloDeluxe_V33802_30_English_Landscape&IMG=Q2Y - Scene 001.mp4']\n",
    "# ['/content/gdrive/MyDrive/Scene-Detection-Version-2/LLC_Training_Data/Unseen_Start/AU_LLC_LightningLinkMultipleIP_V34613_15_AndroidiOSPC_English_Square&IMG=QPH - Scene 001.mp4']\n",
    "# ['/content/gdrive/MyDrive/Scene-Detection-Version-2/LLC_Training_Data/Unseen_Start/ALL_LLC_LightningLinkMultipleIP_V34348_15_AndroidiOSPC_French_Portrait&IMG=QI4 - Scene 001.mp4']\n",
    "# ['/content/gdrive/MyDrive/Scene-Detection-Version-2/LLC_Training_Data/Unseen_Start/AU_LLC_LightningLinkMultipleIP_V34613_15_AndroidiOSPC_English_Square&IMG=QPH - Scene 001.mp4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uBJkekx9pXjS",
    "outputId": "7c6abd61-cdd1-4659-c821-89d3b9319356"
   },
   "outputs": [],
   "source": [
    "# Get basic dimensions of the target\n",
    "target_clip = VideoFileClip(target[0])      \n",
    "# getting only first 5 seconds\n",
    "target_clip = target_clip.subclip(0, 5) \n",
    "# getting clip size\n",
    "height, width = target_clip.size\n",
    "target_size = target_clip.size\n",
    "print(\"Height is :\",height,\"Width is :\",width)\n",
    "print(\"The target size is :\",target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CBeTnVu9-0Oe",
    "outputId": "d60adb91-5d56-4f15-c87d-06a3423d60c3"
   },
   "outputs": [],
   "source": [
    "#Check out tags & colors in the target to show to the user\n",
    "target_tags = df_target_performance.tags[0]\n",
    "target_colors = df_target_performance.primary_color[0]\n",
    "print(target_tags)\n",
    "print(target_colors)\n",
    "#df_mid_performance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ph4s32z6HC8w"
   },
   "outputs": [],
   "source": [
    "# Dimension matching Mid-Scenes & End-Scenes\n",
    "videos_mid_train = videos_mid_train[[list(df_mid_performance.index[df_mid_performance['dimension'] == target_size])]]\n",
    "df_mid_performance = df_mid_performance.loc[list(df_mid_performance.index[df_mid_performance['dimension'] == target_size])]\n",
    "\n",
    "videos_end_train = videos_end_train[[list(df_end_performance.index[df_end_performance['dimension'] == target_size])]]\n",
    "df_end_performance = df_end_performance.loc[list(df_end_performance.index[df_end_performance['dimension'] == target_size])]\n",
    "\n",
    "\n",
    "list_m = list(df_mid_performance.index[df_mid_performance['dimension'] == target_size])\n",
    "#print(list_m)\n",
    "files_mid = [files_mid[i] for i in list_m]\n",
    "list_e = list(df_end_performance.index[df_end_performance['dimension'] == target_size])\n",
    "#print(list_e)\n",
    "files_end = [files_end[i] for i in list_e]\n",
    "\n",
    "df_mid_performance.reset_index(inplace = True, drop = True)\n",
    "df_end_performance.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l6Io-5-pHT5L",
    "outputId": "2357cb84-a7dc-456c-c76c-57d2409cee13"
   },
   "outputs": [],
   "source": [
    "# Checking shape after dimension filtering\n",
    "print(videos_mid_train.shape)\n",
    "print(len(files_mid))\n",
    "print(df_mid_performance.shape)\n",
    "#print(df_mid_performance)\n",
    "print(videos_end_train.shape)\n",
    "print(len(files_end))\n",
    "print(df_end_performance.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "id": "xMZxJqAUHWzV",
    "outputId": "01205177-230c-4bb3-ff3d-a78ef6d05003"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Search for similar tags videos soft search\n",
    "#list(df_mid_performance[['Balcony' in x for x in df_mid_performance['tags']]].index)\n",
    "def tag_search(videos_mid_train,df_mid_performance,videos_end_train,df_end_performance,files_mid,files_end,tag_name):\n",
    "  #Remove exist if else if you want a search for all tags\n",
    "  exist = str(set([tag_name in x for x in df_mid_performance['tags']]))[1:-1] \n",
    "  \n",
    "  videos_mid_train = videos_mid_train[[list(df_mid_performance[[tag_name in x for x in df_mid_performance['tags']]].index)]]\n",
    "  df_mid_performance = df_mid_performance.loc[list(df_mid_performance[[tag_name in x for x in df_mid_performance['tags']]].index)]\n",
    "\n",
    "  videos_end_train = videos_end_train[[list(df_end_performance[[tag_name in x for x in df_end_performance['tags']]].index)]]\n",
    "  df_end_performance = df_end_performance.loc[list(df_end_performance[[tag_name in x for x in df_end_performance['tags']]].index)]\n",
    "\n",
    "\n",
    "  list_m = list(df_mid_performance[[tag_name in x for x in df_mid_performance['tags']]].index)\n",
    "  print(list_m)\n",
    "  files_mid = [files_mid[i] for i in list_m]\n",
    "  list_e = list(df_end_performance[[tag_name in x for x in df_end_performance['tags']]].index)\n",
    "  print(list_e)\n",
    "  files_end = [files_end[i] for i in list_e]\n",
    "\n",
    "  df_mid_performance.reset_index(inplace = True, drop = True)\n",
    "  df_end_performance.reset_index(inplace = True, drop = True)\n",
    "  return tag_name,videos_mid_train,df_mid_performance,videos_end_train,df_end_performance,files_mid,files_end\n",
    "\n",
    "\n",
    "tag_names = ['Animal']\n",
    "for tag_name in tag_names:\n",
    "  tag_res,videos_mid_train,df_mid_performance,videos_end_train,df_end_performance,files_mid,files_end = tag_search(videos_mid_train,df_mid_performance,videos_end_train,df_end_performance,files_mid,files_end,tag_name)\n",
    "  print(tag_res, 'found')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "MJnpLmtJIEZ2",
    "outputId": "a602a631-393f-4a8d-9992-2da43bf8d0f4"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "print(videos_mid_train.shape)\n",
    "print(len(files_mid))\n",
    "print(df_mid_performance.shape)\n",
    "print(videos_end_train.shape)\n",
    "print(len(files_end))\n",
    "print(df_end_performance.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "id": "n3HYLT6vIVnp",
    "outputId": "dd20c0c1-0c5f-479a-db8b-0d27328b5c4d"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "### Function to check primary colors present or not\n",
    "def color_search(videos_mid_train,df_mid_performance,videos_end_train,df_end_performance,files_mid,files_end,color_name):\n",
    "  #Remove exist if else if you want a search for all primary_colors\n",
    "  videos_mid_train = videos_mid_train[[list(df_mid_performance[[color_name in x for x in df_mid_performance['primary_color']]].index)]]\n",
    "  df_mid_performance = df_mid_performance.loc[list(df_mid_performance[[color_name in x for x in df_mid_performance['primary_color']]].index)]\n",
    "\n",
    "  videos_end_train = videos_end_train[[list(df_end_performance[[color_name in x for x in df_end_performance['primary_color']]].index)]]\n",
    "  df_end_performance = df_end_performance.loc[list(df_end_performance[[color_name in x for x in df_end_performance['primary_color']]].index)]\n",
    "\n",
    "\n",
    "  list_m = list(df_mid_performance[[color_name in x for x in df_mid_performance['primary_color']]].index)\n",
    "  print(list_m)\n",
    "  files_mid = [files_mid[i] for i in list_m]\n",
    "  list_e = list(df_end_performance[[color_name in x for x in df_end_performance['primary_color']]].index)\n",
    "  print(list_e)\n",
    "  files_end = [files_end[i] for i in list_e]\n",
    "\n",
    "  df_mid_performance.reset_index(inplace = True, drop = True)\n",
    "  df_end_performance.reset_index(inplace = True, drop = True)\n",
    "  return videos_mid_train,df_mid_performance,videos_end_train,df_end_performance,files_mid,files_end\n",
    "\n",
    "\n",
    "color_name = '#5e53bb'\n",
    "#'#302f766'\n",
    "videos_mid_train,df_mid_performance,videos_end_train,df_end_performance,files_mid,files_end = color_search(videos_mid_train,df_mid_performance,videos_end_train,df_end_performance,files_mid,files_end,color_name)\n",
    "#for color_name in color_names:\n",
    "#  color_res = color_search(videos_mid_train,df_mid_performance,videos_end_train,df_end_performance,files_mid,files_end,color_name)\n",
    "#  print(color_res, 'found')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "C2kOkPLvItyQ",
    "outputId": "a92ff08f-107d-48e2-8dea-abda4bf9dbe8"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "print(videos_mid_train.shape)\n",
    "print(len(files_mid))\n",
    "print(df_mid_performance.shape)\n",
    "print(videos_end_train.shape)\n",
    "print(len(files_end))\n",
    "print(df_end_performance.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8X9zlWB2Kv6J",
    "outputId": "8b644ac9-43a7-4555-d992-c4e738f3f7b0"
   },
   "outputs": [],
   "source": [
    "# Feature Extraction for target variable\n",
    "videos_test = feature_extractor(target,'Target')\n",
    "print(videos_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JOK_JKHeLBIX"
   },
   "outputs": [],
   "source": [
    "# Function to merge the arrays & files of the training mid/end with the target\n",
    "def array_file_merge(video_array,target_array,files_train,target): \n",
    "  array = np.concatenate((video_array,target_array),axis=0)\n",
    "  print(array.shape)\n",
    "  files_t = files_train + target\n",
    "  print(len(files_t))\n",
    "  return array, files_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3jE8uvDRLKsy",
    "outputId": "4f082e4a-34d9-4921-b1a7-0255b9f309cc"
   },
   "outputs": [],
   "source": [
    "arr_mid, files_t = array_file_merge(videos_mid_train,videos_test,files_mid,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LxP6iHNNLTQ-"
   },
   "outputs": [],
   "source": [
    "# compute cosine similarities between videos\n",
    "def cos(arr,files):\n",
    "  cosSimilarities = cosine_similarity(arr)\n",
    "\n",
    "  # store the results into a pandas dataframe\n",
    "\n",
    "  cos_similarities_df = pd.DataFrame(cosSimilarities, columns=files, index=files)\n",
    "  print(cos_similarities_df.shape)\n",
    "  return cos_similarities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z6VffEceT4dt"
   },
   "outputs": [],
   "source": [
    "#df_mid_performance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1wE406xGLXwG"
   },
   "outputs": [],
   "source": [
    "# Consolidation Recommendation Function for next scenes\n",
    "M = []\n",
    "E = []\n",
    "\n",
    "def tag_func(tag,result,position):\n",
    "  if position == 'mid':\n",
    "    data = df_mid_performance[(df_mid_performance.files_path == result)].tags\n",
    "    return list(data)\n",
    "  elif position  == 'end':\n",
    "    data = df_end_performance[(df_end_performance.files_path == result)].tags\n",
    "    return list(data)\n",
    "\n",
    "def color_func(color,result,position):\n",
    "  if position == 'mid':\n",
    "    data = df_mid_performance[(df_mid_performance.files_path == result)].primary_color\n",
    "    return list(data)\n",
    "  elif position  == 'end':\n",
    "    data = df_end_performance[(df_end_performance.files_path == result)].primary_color\n",
    "    return list(data)\n",
    "\n",
    "def retrieve_most_similar_videos(arr,files,given_video,position,tag,color,nb_closest_videos):\n",
    "\n",
    "    cos_similarities_df = cos(arr,files)\n",
    "    print(\"*********************************\")\n",
    "    print(\"Original Add Video:\")\n",
    "    print(\"*********************************\")\n",
    "    print(given_video)\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    print(\"Most Similar Video Recommended:\")\n",
    "\n",
    "    closest_videos = cos_similarities_df[given_video].sort_values(ascending=False)[1:nb_closest_videos+1].index\n",
    "    closest_videos_scores = cos_similarities_df[given_video].sort_values(ascending=False)[1:nb_closest_videos+1]\n",
    "\n",
    "    for i in range(0,len(closest_videos)):\n",
    "        #print(closest_videos[i])\n",
    "        result = closest_videos[i]\n",
    "        print(result)\n",
    "\n",
    "        #Get performance data from the performance dataframe\n",
    "        try:\n",
    "          if position == 'mid':\n",
    "            perf = float(df_mid_performance.query(\"files_path == '{a}'\".format(a=closest_videos[i])).performance)\n",
    "            print('The global performance of video :',perf)\n",
    "\n",
    "            #Function call to check tag & color present or not\n",
    "            tag_check = tag_func(tag,result,position)\n",
    "            tag_check = tag in tag_check[0]\n",
    "            tag_res = 1 if tag_check == True else 0\n",
    "            print('Tag Score is :',tag_res)\n",
    "\n",
    "            color_check = color_func(color,result,position)\n",
    "            color_check = color in color_check[0]\n",
    "            color_res = 1 if color_check == True else 0\n",
    "            print('Color Score is :',color_res)\n",
    "\n",
    "            print(\"Cosine Similarity Score: \",closest_videos_scores[i])\n",
    "            final_score = (closest_videos_scores[i]+perf+tag_res+color_res)*100\n",
    "            cons_score.append(final_score)\n",
    "            print(\"Consolidated Score :\", final_score)\n",
    "            print()\n",
    "            \n",
    "          elif position == 'end':\n",
    "            perf = float(df_end_performance.query(\"files_path == '{a}'\".format(a=closest_videos[i])).performance)\n",
    "            print('The global performance of video :',perf)\n",
    "            #Function call to check tag & color present or not\n",
    "            tag_check = tag_func(tag,result,position)\n",
    "            tag_check = tag in tag_check[0]\n",
    "            tag_res = 1 if tag_check == True else 0\n",
    "            print('Tag score is',tag_res)\n",
    "\n",
    "            color_check = color_func(color,result,position)\n",
    "            color_check = color in color_check[0]\n",
    "            color_res = 1 if color_check == True else 0\n",
    "            print('Color Score is :',color_res)\n",
    "\n",
    "            print(\"Cosine Similarity Score: \",closest_videos_scores[i])\n",
    "            final_score = (closest_videos_scores[i]+perf+tag_res+color_res)*100\n",
    "            cons_score.append(final_score)\n",
    "            print(\"Consolidated Score :\", final_score)\n",
    "\n",
    "        except:\n",
    "            cons_score.append(0)\n",
    "\n",
    "        \n",
    "       # print(\"Cosine Similarity Score: \",closest_videos_scores[i])\n",
    "       # print('The global performance of video :',perf)\n",
    "       # print('The tag score is :',tag_res)\n",
    "       # print('The primary color score:',color_res)\n",
    "        \n",
    "       # print(\"Consolidated Score :\", final_score)\n",
    "        print('---------------------------------------------------------------------')\n",
    "\n",
    "        if position == 'mid':\n",
    "          M.append(closest_videos[i])\n",
    "        elif position == 'end':\n",
    "          E.append(closest_videos[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tqSzKEnGLilD"
   },
   "outputs": [],
   "source": [
    "# Parameter setup for next scene including tags & primary color\n",
    "cons_score = []\n",
    "MIDDLE_SCENES = []\n",
    "start_index = len(files_t)-1\n",
    "tag = 'Clothing'\n",
    "color = '#b14425'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vIjUgZicICCH",
    "outputId": "3853ac60-d6af-4851-9c26-517493b74358"
   },
   "outputs": [],
   "source": [
    "# Calling consilation function to n numbers for times for n number of mid scenes required by the user\n",
    "for clip in range(No_of_mid_scenes):\n",
    "  retrieve_most_similar_videos(arr_mid,files_t,files_t[start_index],'mid',tag,color,3)\n",
    "  print(M)\n",
    "  print(cons_score)\n",
    "  MIDDLE = M[cons_score.index(max(cons_score))]\n",
    "  print(MIDDLE)\n",
    "  MIDDLE_SCENES.append(MIDDLE)\n",
    "  M = []\n",
    "  cons_score = []\n",
    "  # start_index = files_t.index(M[-1])\n",
    "  # print(\"Start index\",start_index)\n",
    "  start_index = files_t.index(MIDDLE_SCENES[-1])\n",
    "  print(\"Start index\",start_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i4furlN7NiZG",
    "outputId": "b7e5b4ed-a9a6-4172-e136-d3dc8cae01e5"
   },
   "outputs": [],
   "source": [
    "print(MIDDLE_SCENES)\n",
    "print(len(MIDDLE_SCENES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_oMKpftQQlvN",
    "outputId": "74e8a174-1fc9-4725-ea82-820a1cd7c3d7"
   },
   "outputs": [],
   "source": [
    "# Setting the last mid scene as a target for the end scene\n",
    "target1 = MIDDLE_SCENES[-1:]\n",
    "target1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mja84YK7QqE_",
    "outputId": "2e5aba5e-2182-45fc-cb30-7d1ea42dca59"
   },
   "outputs": [],
   "source": [
    "#Extract features of the last predicted mid scene\n",
    "videos_test = feature_extractor(target1,'MID')\n",
    "print(videos_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dpRWy_pcQtNa",
    "outputId": "5d781d86-4fcb-4ff7-811a-6531548699f7"
   },
   "outputs": [],
   "source": [
    "arr_end, files_t1 = array_file_merge(videos_end_train,videos_test,files_end,target1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k2i-OWSeQw9P",
    "outputId": "8688a2f5-18a1-4fb9-f344-5e1bec2675b0"
   },
   "outputs": [],
   "source": [
    "# Parameter setup & consolidation function call for the end scenes\n",
    "cons_score = []\n",
    "END_SCENES = []\n",
    "retrieve_most_similar_videos(arr_end,files_t1,files_t1[len(files_t1)-1],'end',tag,color,3)\n",
    "print(E)\n",
    "print(cons_score)\n",
    "END = E[cons_score.index(max(cons_score))]\n",
    "print(E)\n",
    "END_SCENES.append(END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z_p4UwfbQ6Ul",
    "outputId": "b5ab9bee-525f-468c-8833-402e984471e3"
   },
   "outputs": [],
   "source": [
    "END_SCENES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mC_43f8TRKtV"
   },
   "outputs": [],
   "source": [
    "# Name of the directory where we want the splitted scenes to reside\n",
    "if not os.path.exists(f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_RESULT'):\n",
    "    os.makedirs(f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_RESULT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "klB303sISOY-",
    "outputId": "8715a63e-9dbe-43dc-dc6a-72b89208b9a2"
   },
   "outputs": [],
   "source": [
    "START_SCENE = target\n",
    "\n",
    "clip = VideoFileClip(START_SCENE[0])      \n",
    "# getting only first 5 seconds\n",
    "clip = clip.subclip(0, 5) \n",
    "# getting clip size\n",
    "height, width = clip.size\n",
    "print(\"Height is :\",height,\"Width is :\",width)\n",
    "\n",
    "#res = S + M + E\n",
    "res = START_SCENE + MIDDLE_SCENES + END_SCENES\n",
    "\n",
    "# Check to remove duplicacy of videos in the results\n",
    "RESULT = []\n",
    "[RESULT.append(x) for x in res if x not in RESULT]\n",
    "print(RESULT)\n",
    "print(\"Total scenes in result are :\",len(RESULT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OHvk4_jWSd-7",
    "outputId": "4cccc733-44d2-42c7-ebd4-272fb363a03f"
   },
   "outputs": [],
   "source": [
    "# Check dimensions of the predicted scenes along with adding fade in out audio \n",
    "counter = 0\n",
    "final = []\n",
    "for video in RESULT:\n",
    "  video = VideoFileClip(\"{a}\".format(a=video))\n",
    "  print(video.size)\n",
    "  video = video.resize( (height,width) )\n",
    "  video = video.audio_fadein(3.0)\n",
    "  video = video.audio_fadeout(3.0)\n",
    "  final.append(video)\n",
    "  counter += 1\n",
    "\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q3C6cjhRSnR7",
    "outputId": "71fb0af4-95ec-4a8b-c1e6-4255d986395d"
   },
   "outputs": [],
   "source": [
    "# Restiching all clips back\n",
    "final_video= concatenate_videoclips(final)\n",
    "final_video.write_videofile(f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_RESULT/video_merge_nasnet.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xSDpTRBPDVrI",
    "outputId": "10a6ab47-095d-4914-d565-1cc751334bd1"
   },
   "outputs": [],
   "source": [
    "# Restiching all clips back\n",
    "final_video= concatenate_videoclips(final)\n",
    "final_video.write_videofile(f'/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_RESULT/video_merge_inception.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "id": "VVlGuLmHSsmj",
    "outputId": "431fbef0-17d6-4f05-e678-a2152cf5cb5d"
   },
   "outputs": [],
   "source": [
    "# showing final clip\n",
    "final_video.ipython_display(width = 480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "SEIgaAlRDai7",
    "outputId": "88799a68-d11d-45f3-b8c8-c8f0a7acd78c"
   },
   "outputs": [],
   "source": [
    "# showing final clip\n",
    "final_video.ipython_display(width = 480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HtYNAHHfTO8O",
    "outputId": "a0f28f86-0cd5-4e51-baa6-66e0569c6a33"
   },
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "id": "vIy_loWqS2GU",
    "outputId": "388f50ac-421e-4c36-fb13-0da7c22ba87f"
   },
   "outputs": [],
   "source": [
    "videoclip = VideoFileClip(f\"/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_RESULT/video_merge_nasnet.mp4\")\n",
    "#clip_duration = videoclip.duration\n",
    "#audioclip = AudioFileClip(\"/content/gdrive/MyDrive/Scene_Detection/music.mp3\").set_duration(clip_duration)\n",
    "\n",
    "#new_audioclip = CompositeAudioClip([audioclip])\n",
    "#videoclip.audio = new_audioclip\n",
    "\n",
    "name_start_index = target[0].index('LLC')\n",
    "name_end_index = target[0].index(\"- S\")\n",
    "videoclip.write_videofile(f\"/content/gdrive/MyDrive/Scene-Detection-Version-2/{acc_name}_RESULT/{target[0][name_start_index:name_end_index]}.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2PyU2nrTTGR"
   },
   "outputs": [],
   "source": [
    "#any(x in ['b', 'a', 'foo', 'bar'] for x in ['2', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "4wkg9-kwXKNO",
    "outputId": "d62b8092-7aab-49d5-a030-824d69023c83"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "mp4 = open('/content/gdrive/MyDrive/Scene-Detection-Version-2/LLC_RESULT/video_merge_nasnet.mp4','rb').read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "HTML(\"\"\"\n",
    "<video width=400 controls>\n",
    "      <source src=\"%s\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\" % data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "kjObHTCYff47",
    "outputId": "f0d3805c-df0c-4eb6-81aa-5c9e64f19b83"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "mp4 = open('/content/gdrive/MyDrive/Scene-Detection-Version-2/LLC_RESULT/video_merge_nasnet.mp4','rb').read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "HTML(\"\"\"\n",
    "<video width=400 controls>\n",
    "      <source src=\"%s\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\" % data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "2IzgityTf77W",
    "outputId": "3687efc8-2886-49fb-bf19-c47d4a2e37d5"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "mp4 = open('/content/gdrive/MyDrive/Scene-Detection-Version-2/LLC_RESULT/video_merge_nasnet.mp4','rb').read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "HTML(\"\"\"\n",
    "<video width=400 controls>\n",
    "      <source src=\"%s\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\" % data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hb6I8TM1gEsL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Model_Consilation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
